2021-12-26 00:07:42.777  INFO 18088 --- [cluster-ClusterId{value='61c762c52917e801ff88529f', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketReadException: Exception receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:707) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:579) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:415) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:342) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.CommandHelper.sendAndReceive(CommandHelper.java:96) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.CommandHelper.executeCommand(CommandHelper.java:44) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.initializeConnectionDescription(InternalStreamConnectionInitializer.java:131) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.startHandshake(InternalStreamConnectionInitializer.java:73) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:182) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:188) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:152) ~[mongodb-driver-core-4.4.0.jar:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.io.IOException: The connection to the server was closed
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener$1.operationComplete(NettyStream.java:511) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener$1.operationComplete(NettyStream.java:508) ~[mongodb-driver-core-4.4.0.jar:na]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1182) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:773) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:749) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:620) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.closeOnRead(AbstractNioByteChannel.java:105) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:174) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	... 1 common frames omitted

2021-12-26 00:09:30.223  INFO 18088 --- [cluster-rtt-ClusterId{value='61c762c52917e801ff88529f', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:132, serverValue:2}] to localhost:27017
2021-12-26 00:09:30.223  INFO 18088 --- [cluster-ClusterId{value='61c762c52917e801ff88529f', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:131, serverValue:1}] to localhost:27017
2021-12-26 00:09:30.224  INFO 18088 --- [cluster-ClusterId{value='61c762c52917e801ff88529f', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=5618433900}
2021-12-26 00:12:30.444  INFO 18088 --- [RMI TCP Connection(24)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2021-12-26 00:13:15.442  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:13:15.443  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:13:16.188  INFO 16408 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2021-12-26 00:13:16.189  INFO 16408 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2021-12-26 00:13:21.151  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:13:21.850  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 692 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:13:25.379  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:13:26.515  INFO 16408 --- [cluster-ClusterId{value='61c7664d3338fd7765883e80', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
2021-12-26 00:13:26.515  INFO 16408 --- [cluster-rtt-ClusterId{value='61c7664d3338fd7765883e80', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:5}] to localhost:27017
2021-12-26 00:13:26.516  INFO 16408 --- [cluster-ClusterId{value='61c7664d3338fd7765883e80', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=167914500}
2021-12-26 00:13:26.564  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:13:29.540  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:13:29.605  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 15.633 seconds (JVM running for 31.216)
2021-12-26 00:14:54.258  INFO 16408 --- [reactor-http-nio-3] o.springdoc.api.AbstractOpenApiResource  : Init duration for springdoc-openapi is: 309 ms
2021-12-26 00:17:36.737  INFO 16408 --- [reactor-http-nio-5] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = hotel-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class com.fasterxml.jackson.databind.JsonSerializer

2021-12-26 00:17:36.940  INFO 16408 --- [reactor-http-nio-5] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=hotel-producer] Closing the Kafka producer with timeoutMillis = 0 ms.
2021-12-26 00:17:36.940  INFO 16408 --- [reactor-http-nio-5] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2021-12-26 00:17:36.940  INFO 16408 --- [reactor-http-nio-5] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2021-12-26 00:17:36.941  INFO 16408 --- [reactor-http-nio-5] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2021-12-26 00:17:36.943  INFO 16408 --- [reactor-http-nio-5] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for hotel-producer unregistered
2021-12-26 00:17:37.190 ERROR 16408 --- [reactor-http-nio-5] reactor.core.publisher.Operators         : Operator called default onErrorDropped

reactor.core.Exceptions$ErrorCallbackNotImplemented: org.apache.kafka.common.KafkaException: Failed to construct kafka producer
Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka producer
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:439) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:290) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.ProducerFactory.createProducer(ProducerFactory.java:34) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.DefaultKafkaSender.lambda$new$0(DefaultKafkaSender.java:99) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.MonoCallable.call(MonoCallable.java:92) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxSubscribeOnCallable$CallableSubscribeOnSubscription.run(FluxSubscribeOnCallable.java:227) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.ImmediateScheduler.schedule(ImmediateScheduler.java:52) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoSubscribeOnCallable.subscribe(MonoSubscribeOnCallable.java:52) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoCacheTime.subscribeOrReturn(MonoCacheTime.java:143) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8455) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribeWith(Flux.java:8642) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8439) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8363) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8281) ~[reactor-core-3.4.12.jar:3.4.12]
	at com.cts.hotel.service.impl.HotelInventoryServiceImpl.createRoom(HotelInventoryServiceImpl.java:62) ~[main/:na]
	at com.cts.hotel.controller.HotelInventoryController.createRoom(HotelInventoryController.java:46) ~[main/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:144) ~[spring-webflux-5.3.13.jar:5.3.13]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:125) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:251) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:336) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:101) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onNext(FluxPeek.java:200) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:295) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:159) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:400) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:419) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:590) ~[reactor-netty-http-1.0.13.jar:1.0.13]
	at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:93) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:264) ~[reactor-netty-http-1.0.13.jar:1.0.13]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.apache.kafka.common.KafkaException: Could not instantiate class com.fasterxml.jackson.databind.JsonSerializer
	at org.apache.kafka.common.utils.Utils.newInstance(Utils.java:394) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:399) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:434) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:419) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:373) ~[kafka-clients-3.0.0.jar:na]
	... 70 common frames omitted
Caused by: java.lang.InstantiationException: null
	at java.base/jdk.internal.reflect.InstantiationExceptionConstructorAccessorImpl.newInstance(InstantiationExceptionConstructorAccessorImpl.java:48) ~[na:na]
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499) ~[na:na]
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480) ~[na:na]
	at org.apache.kafka.common.utils.Utils.newInstance(Utils.java:390) ~[kafka-clients-3.0.0.jar:na]
	... 74 common frames omitted

2021-12-26 00:22:39.219  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:22:39.219  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:22:39.985  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:22:39.996  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 10 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:22:40.062  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:22:40.084  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:22:40.116  INFO 16408 --- [cluster-rtt-ClusterId{value='61c768783338fd7765883e81', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:6}] to localhost:27017
2021-12-26 00:22:40.229  INFO 16408 --- [cluster-ClusterId{value='61c768783338fd7765883e81', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:7}] to localhost:27017
2021-12-26 00:22:40.230  INFO 16408 --- [cluster-ClusterId{value='61c768783338fd7765883e81', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=164380800}
2021-12-26 00:22:40.373  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:22:40.384  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 1.31 seconds (JVM running for 581.995)
2021-12-26 00:22:40.389  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:24:00.759  INFO 16408 --- [reactor-http-nio-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = hotel-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.boot.jackson.JsonObjectSerializer

2021-12-26 00:24:00.760  INFO 16408 --- [reactor-http-nio-2] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=hotel-producer] Closing the Kafka producer with timeoutMillis = 0 ms.
2021-12-26 00:24:00.760  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2021-12-26 00:24:00.760  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2021-12-26 00:24:00.760  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2021-12-26 00:24:00.761  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for hotel-producer unregistered
2021-12-26 00:24:00.765 ERROR 16408 --- [reactor-http-nio-2] reactor.core.publisher.Operators         : Operator called default onErrorDropped

reactor.core.Exceptions$ErrorCallbackNotImplemented: org.apache.kafka.common.KafkaException: Failed to construct kafka producer
Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka producer
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:439) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:290) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.ProducerFactory.createProducer(ProducerFactory.java:34) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.DefaultKafkaSender.lambda$new$0(DefaultKafkaSender.java:99) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.MonoCallable.call(MonoCallable.java:92) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxSubscribeOnCallable$CallableSubscribeOnSubscription.run(FluxSubscribeOnCallable.java:227) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.ImmediateScheduler.schedule(ImmediateScheduler.java:52) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoSubscribeOnCallable.subscribe(MonoSubscribeOnCallable.java:52) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoCacheTime.subscribeOrReturn(MonoCacheTime.java:143) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8455) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribeWith(Flux.java:8642) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8439) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8363) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Flux.subscribe(Flux.java:8281) ~[reactor-core-3.4.12.jar:3.4.12]
	at com.cts.hotel.service.impl.HotelInventoryServiceImpl.createRoom(HotelInventoryServiceImpl.java:62) ~[main/:na]
	at com.cts.hotel.controller.HotelInventoryController.createRoom(HotelInventoryController.java:46) ~[main/:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:144) ~[spring-webflux-5.3.13.jar:5.3.13]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:125) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:251) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:336) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:101) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onNext(FluxPeek.java:200) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:295) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:159) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:400) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:419) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:590) ~[reactor-netty-http-1.0.13.jar:1.0.13]
	at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:93) ~[reactor-netty-core-1.0.13.jar:1.0.13]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:264) ~[reactor-netty-http-1.0.13.jar:1.0.13]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: org.apache.kafka.common.KafkaException: Could not instantiate class org.springframework.boot.jackson.JsonObjectSerializer
	at org.apache.kafka.common.utils.Utils.newInstance(Utils.java:394) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:399) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:434) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:419) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:373) ~[kafka-clients-3.0.0.jar:na]
	... 70 common frames omitted
Caused by: java.lang.InstantiationException: null
	at java.base/jdk.internal.reflect.InstantiationExceptionConstructorAccessorImpl.newInstance(InstantiationExceptionConstructorAccessorImpl.java:48) ~[na:na]
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499) ~[na:na]
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480) ~[na:na]
	at org.apache.kafka.common.utils.Utils.newInstance(Utils.java:390) ~[kafka-clients-3.0.0.jar:na]
	... 74 common frames omitted

2021-12-26 00:26:29.631  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:26:29.632  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:26:29.977  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:26:29.988  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 10 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:26:30.068  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:26:30.074  INFO 16408 --- [cluster-ClusterId{value='61c7695e3338fd7765883e82', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:5, serverValue:9}] to localhost:27017
2021-12-26 00:26:30.074  INFO 16408 --- [cluster-rtt-ClusterId{value='61c7695e3338fd7765883e82', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:6, serverValue:8}] to localhost:27017
2021-12-26 00:26:30.074  INFO 16408 --- [cluster-ClusterId{value='61c7695e3338fd7765883e82', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3574000}
2021-12-26 00:26:30.087  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:26:30.317  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:26:30.320  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 0.72 seconds (JVM running for 811.93)
2021-12-26 00:26:30.321  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:26:37.019  INFO 16408 --- [reactor-http-nio-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = hotel-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-12-26 00:26:37.336  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.0.0
2021-12-26 00:26:37.336  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 8cb0a5e9d3441962
2021-12-26 00:26:37.336  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1640458597334
2021-12-26 00:26:37.345  INFO 16408 --- [reactor-http-nio-2] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=hotel-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2021-12-26 00:26:37.346 ERROR 16408 --- [reactor-kafka-sender-1214553539] r.k.sender.internals.DefaultKafkaSender  : Sender failed

java.lang.IllegalStateException: Cannot perform operation after producer has been closed
	at org.apache.kafka.clients.producer.KafkaProducer.throwIfProducerClosed(KafkaProducer.java:896) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:905) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:889) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:114) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:40) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.12.jar:3.4.12]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2021-12-26 00:26:37.347 ERROR 16408 --- [reactor-kafka-sender-1214553539] reactor.core.publisher.Operators         : Operator called default onErrorDropped

reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.IllegalStateException: Cannot perform operation after producer has been closed
Caused by: java.lang.IllegalStateException: Cannot perform operation after producer has been closed
	at org.apache.kafka.clients.producer.KafkaProducer.throwIfProducerClosed(KafkaProducer.java:896) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:905) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:889) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:114) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:40) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.12.jar:3.4.12]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2021-12-26 00:26:38.124  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2021-12-26 00:26:38.125  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2021-12-26 00:26:38.125  INFO 16408 --- [reactor-http-nio-2] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2021-12-26 00:26:38.125  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for hotel-producer unregistered
2021-12-26 00:26:38.157 ERROR 16408 --- [reactor-http-nio-2] a.w.r.e.AbstractErrorWebExceptionHandler : [76cd0dfc-1]  500 Server Error for HTTP POST "/v1/hotel"

java.lang.IllegalStateException: Could not resolve parameter [1] in public java.lang.Object com.cts.hotel.exception.GlobalExceptionHandler.handleAnyException(java.lang.Exception,org.springframework.web.context.request.WebRequest): No suitable resolver
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:195) ~[spring-webflux-5.3.13.jar:5.3.13]
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Error has been observed at the following site(s):
	*__checkpoint ? HTTP POST "/v1/hotel" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at org.springframework.web.reactive.result.method.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:195) ~[spring-webflux-5.3.13.jar:5.3.13]
		at org.springframework.web.reactive.result.method.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:136) ~[spring-webflux-5.3.13.jar:5.3.13]
		at org.springframework.web.reactive.result.method.annotation.RequestMappingHandlerAdapter.handleException(RequestMappingHandlerAdapter.java:226) ~[spring-webflux-5.3.13.jar:5.3.13]
		at org.springframework.web.reactive.result.method.annotation.RequestMappingHandlerAdapter.lambda$handle$0(RequestMappingHandlerAdapter.java:195) ~[spring-webflux-5.3.13.jar:5.3.13]
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onError(FluxPeek.java:222) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onError(FluxPeek.java:222) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoIgnoreThen$ThenIgnoreMain.onError(MonoIgnoreThen.java:270) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:251) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:336) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:101) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onNext(FluxPeek.java:200) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:295) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:159) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:142) ~[reactor-core-3.4.12.jar:3.4.12]
		at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:400) ~[reactor-netty-core-1.0.13.jar:1.0.13]
		at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:419) ~[reactor-netty-core-1.0.13.jar:1.0.13]
		at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:590) ~[reactor-netty-http-1.0.13.jar:1.0.13]
		at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:93) ~[reactor-netty-core-1.0.13.jar:1.0.13]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:264) ~[reactor-netty-http-1.0.13.jar:1.0.13]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:324) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:296) ~[netty-codec-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
		at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2021-12-26 00:27:29.136  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:27:29.136  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:27:29.239  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:27:29.248  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 9 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:27:29.323  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:27:29.332  INFO 16408 --- [cluster-rtt-ClusterId{value='61c769993338fd7765883e83', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:8, serverValue:11}] to localhost:27017
2021-12-26 00:27:29.341  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:27:29.346  INFO 16408 --- [cluster-ClusterId{value='61c769993338fd7765883e83', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:7, serverValue:10}] to localhost:27017
2021-12-26 00:27:29.346  INFO 16408 --- [cluster-ClusterId{value='61c769993338fd7765883e83', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=18681800}
2021-12-26 00:27:29.603  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:27:29.613  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 0.495 seconds (JVM running for 871.223)
2021-12-26 00:27:29.617  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:27:49.482  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:27:49.482  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:27:49.577  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:27:49.586  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 9 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:27:49.636  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:27:49.641  INFO 16408 --- [cluster-ClusterId{value='61c769ad3338fd7765883e84', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:9, serverValue:13}] to localhost:27017
2021-12-26 00:27:49.641  INFO 16408 --- [cluster-ClusterId{value='61c769ad3338fd7765883e84', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3264700}
2021-12-26 00:27:49.648  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:27:49.668  INFO 16408 --- [cluster-rtt-ClusterId{value='61c769ad3338fd7765883e84', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:10, serverValue:12}] to localhost:27017
2021-12-26 00:27:49.845  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:27:49.848  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 0.383 seconds (JVM running for 891.459)
2021-12-26 00:27:49.850  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:27:59.935  INFO 16408 --- [reactor-http-nio-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = hotel-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-12-26 00:27:59.939  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.0.0
2021-12-26 00:27:59.939  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 8cb0a5e9d3441962
2021-12-26 00:27:59.939  INFO 16408 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1640458679939
2021-12-26 00:28:00.551  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 1 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:00.553  INFO 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=hotel-producer] Cluster ID: QhkVNIpUSX6QohTPBbAQvA
2021-12-26 00:28:00.718  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 3 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:00.825  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 4 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:00.931  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 5 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.047  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 6 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.176  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 7 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.281  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 8 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.390  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 9 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.514  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 10 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.619  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 11 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.749  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 12 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.862  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 13 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:01.970  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 14 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.084  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 15 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.191  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 16 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.298  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 17 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.415  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 18 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.523  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 19 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.631  WARN 16408 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.NetworkClient   : [Producer clientId=hotel-producer] Error while fetching metadata with correlation id 20 : {add_room=LEADER_NOT_AVAILABLE}
2021-12-26 00:28:02.741 ERROR 16408 --- [reactor-kafka-sender-265645894] r.k.sender.internals.DefaultKafkaSender  : Sender failed

org.apache.kafka.common.errors.SerializationException: Can't convert value of class com.cts.hotel.model.RoomModel to class org.apache.kafka.common.serialization.StringSerializer specified in value.serializer
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:932) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:889) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:114) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:40) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.12.jar:3.4.12]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.lang.ClassCastException: class com.cts.hotel.model.RoomModel cannot be cast to class java.lang.String (com.cts.hotel.model.RoomModel is in unnamed module of loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader @faf588a; java.lang.String is in module java.base of loader 'bootstrap')
	at org.apache.kafka.common.serialization.StringSerializer.serialize(StringSerializer.java:29) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.serialization.Serializer.serialize(Serializer.java:62) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:929) ~[kafka-clients-3.0.0.jar:na]
	... 12 common frames omitted

2021-12-26 00:28:02.741 ERROR 16408 --- [reactor-kafka-sender-265645894] reactor.core.publisher.Operators         : Operator called default onErrorDropped

reactor.core.Exceptions$ErrorCallbackNotImplemented: org.apache.kafka.common.errors.SerializationException: Can't convert value of class com.cts.hotel.model.RoomModel to class org.apache.kafka.common.serialization.StringSerializer specified in value.serializer
Caused by: org.apache.kafka.common.errors.SerializationException: Can't convert value of class com.cts.hotel.model.RoomModel to class org.apache.kafka.common.serialization.StringSerializer specified in value.serializer
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:932) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:889) ~[kafka-clients-3.0.0.jar:na]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:114) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.kafka.sender.internals.SendSubscriber.onNext(SendSubscriber.java:40) ~[reactor-kafka-1.3.8.jar:1.3.8]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.12.jar:3.4.12]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.12.jar:3.4.12]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.lang.ClassCastException: class com.cts.hotel.model.RoomModel cannot be cast to class java.lang.String (com.cts.hotel.model.RoomModel is in unnamed module of loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader @faf588a; java.lang.String is in module java.base of loader 'bootstrap')
	at org.apache.kafka.common.serialization.StringSerializer.serialize(StringSerializer.java:29) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.common.serialization.Serializer.serialize(Serializer.java:62) ~[kafka-clients-3.0.0.jar:na]
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:929) ~[kafka-clients-3.0.0.jar:na]
	... 12 common frames omitted

2021-12-26 00:28:40.311  INFO 16408 --- [Thread-45] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=hotel-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2021-12-26 00:28:40.315  INFO 16408 --- [Thread-45] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2021-12-26 00:28:40.315  INFO 16408 --- [Thread-45] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2021-12-26 00:28:40.315  INFO 16408 --- [Thread-45] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2021-12-26 00:28:40.316  INFO 16408 --- [Thread-45] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for hotel-producer unregistered
2021-12-26 00:28:44.522  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:28:44.523  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:28:44.695  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:28:44.705  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 9 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:28:44.753  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:28:44.767  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:28:45.178  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:28:45.184  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 0.676 seconds (JVM running for 946.794)
2021-12-26 00:28:45.186  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:28:45.535  INFO 16408 --- [cluster-rtt-ClusterId{value='61c769e43338fd7765883e85', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:12, serverValue:14}] to localhost:27017
2021-12-26 00:28:45.535  INFO 16408 --- [cluster-ClusterId{value='61c769e43338fd7765883e85', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:11, serverValue:15}] to localhost:27017
2021-12-26 00:28:45.536  INFO 16408 --- [cluster-ClusterId{value='61c769e43338fd7765883e85', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=779769800}
2021-12-26 00:28:51.830  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 16408 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:28:51.830  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:28:51.923  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:28:51.932  INFO 16408 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 8 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:28:51.982  INFO 16408 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:28:51.989  INFO 16408 --- [cluster-ClusterId{value='61c769eb3338fd7765883e86', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:13, serverValue:17}] to localhost:27017
2021-12-26 00:28:51.989  INFO 16408 --- [cluster-ClusterId{value='61c769eb3338fd7765883e86', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4108200}
2021-12-26 00:28:51.998  INFO 16408 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:28:52.105  INFO 16408 --- [cluster-rtt-ClusterId{value='61c769eb3338fd7765883e86', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:14, serverValue:16}] to localhost:27017
2021-12-26 00:28:52.181  INFO 16408 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:28:52.185  INFO 16408 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 0.372 seconds (JVM running for 953.795)
2021-12-26 00:28:52.186  INFO 16408 --- [restartedMain] .ConditionEvaluationDeltaLoggingListener : Condition evaluation unchanged
2021-12-26 00:28:58.715  INFO 16408 --- [RMI TCP Connection(34)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2021-12-26 00:32:27.001  INFO 6528 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 6528 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:32:27.003  INFO 6528 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:32:27.046  INFO 6528 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2021-12-26 00:32:27.046  INFO 6528 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2021-12-26 00:32:27.516  INFO 6528 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:32:27.629  INFO 6528 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 107 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:32:28.167  INFO 6528 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:32:28.362  INFO 6528 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:32:28.382  INFO 6528 --- [cluster-ClusterId{value='61c76ac4c1645376dd89209e', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:18}] to localhost:27017
2021-12-26 00:32:28.382  INFO 6528 --- [cluster-ClusterId{value='61c76ac4c1645376dd89209e', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=71215200}
2021-12-26 00:32:28.707  INFO 6528 --- [cluster-rtt-ClusterId{value='61c76ac4c1645376dd89209e', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:19}] to localhost:27017
2021-12-26 00:32:30.197  INFO 6528 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:32:30.209  INFO 6528 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 3.517 seconds (JVM running for 4.639)
2021-12-26 00:32:38.567  INFO 6528 --- [reactor-http-nio-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = hotel-producer
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2021-12-26 00:32:38.616  INFO 6528 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.0.0
2021-12-26 00:32:38.618  INFO 6528 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 8cb0a5e9d3441962
2021-12-26 00:32:38.618  INFO 6528 --- [reactor-http-nio-2] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1640458958615
2021-12-26 00:32:38.898  INFO 6528 --- [kafka-producer-network-thread | hotel-producer] org.apache.kafka.clients.Metadata        : [Producer clientId=hotel-producer] Cluster ID: QhkVNIpUSX6QohTPBbAQvA
2021-12-26 00:34:17.187  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2021-12-26 00:34:17.192  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=hotel-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2021-12-26 00:34:17.197  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2021-12-26 00:34:17.197  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2021-12-26 00:34:17.197  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2021-12-26 00:34:17.198  INFO 6528 --- [RMI TCP Connection(11)-127.0.0.1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for hotel-producer unregistered
2021-12-26 00:34:23.271  INFO 17724 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Starting HotelInventoryApplication using Java 17.0.1 on Abhideep with PID 17724 (C:\GitHub\hotel-inventory\bin\main started by abhid in C:\GitHub\hotel-inventory)
2021-12-26 00:34:23.273  INFO 17724 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : No active profile set, falling back to default profiles: default
2021-12-26 00:34:23.314  INFO 17724 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2021-12-26 00:34:23.314  INFO 17724 --- [restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2021-12-26 00:34:23.788  INFO 17724 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2021-12-26 00:34:23.899  INFO 17724 --- [restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 106 ms. Found 4 Reactive MongoDB repository interfaces.
2021-12-26 00:34:24.376  INFO 17724 --- [restartedMain] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2021-12-26 00:34:24.555  INFO 17724 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2021-12-26 00:34:24.597  INFO 17724 --- [cluster-rtt-ClusterId{value='61c76b384017160d4e4d5b72', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:20}] to localhost:27017
2021-12-26 00:34:24.597  INFO 17724 --- [cluster-ClusterId{value='61c76b384017160d4e4d5b72', description='null'}-localhost:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:21}] to localhost:27017
2021-12-26 00:34:24.597  INFO 17724 --- [cluster-ClusterId{value='61c76b384017160d4e4d5b72', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=79818400}
2021-12-26 00:34:25.391  INFO 17724 --- [restartedMain] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 7080
2021-12-26 00:34:25.401  INFO 17724 --- [restartedMain] com.cts.hotel.HotelInventoryApplication  : Started HotelInventoryApplication in 2.455 seconds (JVM running for 3.174)
2021-12-26 00:34:31.182  INFO 17724 --- [cluster-ClusterId{value='61c76b384017160d4e4d5b72', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketReadException: Exception receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:707) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:579) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:415) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:374) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:216) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:152) ~[mongodb-driver-core-4.4.0.jar:na]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: java.io.IOException: The connection to the server was closed
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener$1.operationComplete(NettyStream.java:511) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener$1.operationComplete(NettyStream.java:508) ~[mongodb-driver-core-4.4.0.jar:na]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:1182) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:773) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:749) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:620) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.closeOnRead(AbstractNioByteChannel.java:105) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:174) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	... 1 common frames omitted

2021-12-26 00:34:41.720  INFO 17724 --- [cluster-ClusterId{value='61c76b384017160d4e4d5b72', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketOpenException: Exception opening socket
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener.operationComplete(NettyStream.java:520) ~[mongodb-driver-core-4.4.0.jar:na]
	at com.mongodb.connection.netty.NettyStream$OpenChannelFutureListener.operationComplete(NettyStream.java:488) ~[mongodb-driver-core-4.4.0.jar:na]
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:571) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:550) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:609) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:321) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:337) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information: localhost/[0:0:0:0:0:0:0:1]:27017
Caused by: java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946) ~[na:na]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) ~[netty-transport-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.70.Final.jar:4.1.70.Final]
	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]

2021-12-26 00:35:32.917  INFO 17724 --- [RMI TCP Connection(7)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
